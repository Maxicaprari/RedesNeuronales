# Autoencoder y Clasificador Convolucional para Fashion-MNIST  

Este repositorio contiene la implementaci贸n y an谩lisis de un **Autoencoder Convolucional** y un **Clasificador Convolucional** aplicados al dataset **Fashion-MNIST**. El objetivo del proyecto es estudiar c贸mo distintas configuraciones del espacio latente afectan la reconstrucci贸n de im谩genes y evaluar el desempe帽o de **encoders pre-entrenados** reutilizados en tareas de clasificaci贸n.  

##  Arquitecturas  

### 1. Autoencoder Convolucional  
- **Encoder**: Red convolucional con varias capas de convoluci贸n y *max-pooling* para reducir progresivamente la dimensi贸n de las im谩genes y capturar representaciones latentes.  
- **Latent Space**: Configurable, lo que permite controlar el nivel de compresi贸n.  
- **Decoder**: Red convolucional transpuesta para reconstruir las im谩genes a partir del espacio latente.  

### 2. Clasificador Convolucional  
- **Entrenado desde cero**: Red convolucional est谩ndar entrenada directamente para la tarea de clasificaci贸n.  
- **Con encoder pre-entrenado**: Se reutiliza el encoder del autoencoder para inicializar el clasificador, comparando diferentes estrategias de entrenamiento:  
  - **Transfer learning**: Congelando los pesos del encoder pre-entrenado.  
  - **Fine-tuning**: Ajustando los pesos del encoder, aunque esto llev贸 a sobreajuste.  

---

##  Estructura del Repositorio  

### 1. Carpetas principales  
- **Resultados/**: Contiene gr谩ficos, matrices de confusi贸n y archivos de resultados del entrenamiento y validaci贸n.  

### 2. Archivos de c贸digo   

- `2capas_no_lineal_bn32.py`: Red feedforward con dos capas ocultas, activaciones ReLU y tama帽o de lote de 30.  
- `loops_clasificador.py`: C贸digo para los loops de entrenamiento y validaci贸n del clasificador.  
- `matriz_de_confusi贸n.py`: Genera y visualiza la matriz de confusi贸n para evaluar el desempe帽o del clasificador.  
- `clasificador_para_autoencoder_1capa_nolineal.py`: Clasificador que utiliza representaciones generadas por un autoencoder de una capa no lineal.  
- `clasificador_sin_preentrenar_1.py` y `c贸digo_completo_clasificador_sin_preentrenar.py`: Clasificador desarrollado sin preentrenamiento con autoencoders.  

### 3. Arquitecturas de Autoencoders   

- `arquitectura_1_autoencoder.py`: Autoencoder b谩sico de una sola capa.  
- `arquitectura_2_autoencoder(3_capas).py`: Autoencoder m谩s profundo con tres capas ocultas.  
- `arquitectura_3_autoencoder(1capa).py` y `arquitectura_3_autoencoder(1capa,_no_lineal).py`: Autoencoders de una capa con activaciones no lineales para mejor representaci贸n de las caracter铆sticas.  
- `arquitectura_autoencoder_no__lineal_1.py`: Versi贸n alternativa del autoencoder no lineal.  

---

##  Resultados  

### Clasificador con Encoder pre-entrenado  
- Ofrece una mejor representaci贸n inicial, acelerando la convergencia en las primeras 茅pocas.  
- Para alcanzar el mejor desempe帽o, fue necesario ajustar el modelo para la tarea espec铆fica de clasificaci贸n.  

### Clasificador entrenado desde cero  
- Requiere m谩s tiempo de entrenamiento, pero logra mejores resultados cuando se optimiza correctamente.  

> **Nota**: Los **autoencoders no lineales** no tienen capas lineales intermedias, lo que mejora la representaci贸n de las caracter铆sticas complejas.  

---

## 锔 Requisitos  

- Python 3.x  
- PyTorch  
- Numpy  
- Matplotlib  

---

##  Referencias  

1. Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press. Cap铆tulo 9, "Convolutional Networks".  
2. G茅ron, A. (2019). *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow*. OReilly Media.  
3. LeCun, Y., Bengio, Y., & Hinton, G. (2015). *Deep Learning*. *Nature*, 521(7553), 436-444.  
4. Stanford University. *CS231n: Convolutional Neural Networks for Visual Recognition*. Disponible en: [http://cs231n.stanford.edu/](http://cs231n.stanford.edu/)  
5. Chollet, F. (2017). *Deep Learning with Python*. Manning Publications.  

